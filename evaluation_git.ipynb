{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f43984-1f14-442e-b4d4-26f60062c678",
   "metadata": {},
   "source": [
    "# Evaluation - stage cartographie de l'écosystème\n",
    "\n",
    "Ce notebook est à réaliser chez soi dans un délai de 2 jours, mais rassurez-vous, ça ne prend pas autant de temps ! Il a pour objectif d'évaluer certaines de vos capacités en code et vos bonnes pratiques en scraping, NLP (Natural Language Processing) et manipulation d'API.\n",
    "\n",
    "L'objectif de ce notebook n'est pas de produire des outils opérationnels, mais d'évaluer vos compétences ou votre capacité à chercher des informations.\n",
    "\n",
    "En cas de doute ou de question, n'hésitez pas à nous écrire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e601cb69",
   "metadata": {},
   "source": [
    "# 0. Git\n",
    "\n",
    "La première chose à faire est de \"récupérer\" ce notebook pour le compléter. Plusieurs options selon votre maîtrise de Git et/ou que vous ayez un compte :\n",
    "- fork le repo suivant et le compléter sur un projet perso\n",
    "- vous ajouter au projet, créez votre branch `submission_nomprenom` et push dessus\n",
    "- vous envoyez par mail le notebook à compléter et renvoyer par mail\n",
    "\n",
    "https://github.com/TitouanBlaize/carto_affi/blob/main/evaluation_git.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea047399-f5e2-4c73-888e-aeb969972f5c",
   "metadata": {},
   "source": [
    "## 1. NLP\n",
    "\n",
    "Cette première partie évalue vos connaissance des packages de NLP et vos bonnes pratiques quant au preprocessing de texte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929e7fb-77d9-4eb6-aae0-e87407b36678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# écrivez ici une liste de librairies que vous connaissez pour faire du NLP\n",
    "import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7a5a7-b127-40b1-a502-a027b91f25d7",
   "metadata": {},
   "source": [
    "Dans une première sous-partie, nous vous proposons de coder un pipeline/fonction de preprocessing de données textuelles. \n",
    "\n",
    "L'objectif est, à partir de textes bruts, de produire des textes propres (ponctuation, casse, pluriel, enlever les stopwords,...) qui peuvent être utilisés en entrée d'un pipeline d'apprentissage/fonction. \n",
    "Libre à vous d'inclure et d'implémenter toutes les fonctions de nettoyage que vous souhaitez.\n",
    "Ces opérations peuvent être menées au sein d'une classe (cf class NLPPipeline) ou d'une fonction (NLP_cleaning), comme vous préférez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef2263-ac24-4943-8e30-7c7049f85f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via une classe (\"Orienté objet\")\n",
    "class NLPPipeline():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, x):\n",
    "        pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ff353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via une fonction\n",
    "def NLP_cleaning():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54064e06-0c87-465d-bfe8-80a1f5af35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = NLPPipeline()\n",
    "pipeline.transform(\"Georges Washington, 1er président des USA, habite à Washington.\")\n",
    "# Ou NLP_cleaning(\"Georges Washington, 1er président des USA, habite à Washington.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b90180",
   "metadata": {},
   "source": [
    "On pourra par exemple essayer d'obtenir `georges washington er president usa habite a washington`, il n'y a pas de \"bon\" résultat, libre à vous d'ajouter plusieurs cleaning de textes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c342679-5a98-4e43-9260-deb132c6ba10",
   "metadata": {},
   "source": [
    "## 2. Scraping/API\n",
    "\n",
    "Dans cette deuxième partie, nous vous proposons d'écrire une petite fonction de scraping.\n",
    "\n",
    "A l'aide de la librairie de votre choix, écrivez une fonction qui permet de trouver le nombre de citations d'un article sur Pubmed.   \n",
    "Vous appliquerez la fonction à l'article suivant: \"New onset refractory status epilepticus (NORSE) *C. Sculier, N. Gaspard*, 2019\" dont l'ID Pubmed est 30482654\n",
    "\n",
    "https://pubmed.ncbi.nlm.nih.gov/30482654/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990bfcbf-7531-4b5d-98c4-df5610e2d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ... import ...\n",
    "import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01bf9f-ea70-4a29-be37-3185b5eabf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_citations(pubmed_id):\n",
    "    \"\"\"\n",
    "    get the number of citations of a given pubmed article\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb972d2",
   "metadata": {},
   "source": [
    "En runnant la case suivante on est censé obtenir 19, bonne chance !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67337264-c9ad-4fed-85f2-f7ce96cb35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_number_of_citations(30482654)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
